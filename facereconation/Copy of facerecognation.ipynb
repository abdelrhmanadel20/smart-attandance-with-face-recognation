{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of facerecognation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pWovBqFnqh3R","colab_type":"text"},"source":["imports"]},{"cell_type":"code","metadata":{"id":"2s69tDNLqblg","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os.path\n","\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOBcJGqQruPZ","colab_type":"text"},"source":["aline faces"]},{"cell_type":"code","metadata":{"id":"-4-XoHkXrtoV","colab_type":"code","colab":{}},"source":["import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","from align import AlignDlib\n","\n","%matplotlib inline\n","\n","def load_image(path):\n","    img = cv2.imread(path, 1)\n","    # OpenCV loads images with color channels\n","    # in BGR order. So we need to reverse them\n","    return img[...,::-1]\n","def align_image(img):\n","    return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), \n","                           landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kxHBbqSFqkO4","colab_type":"text"},"source":["load model"]},{"cell_type":"code","metadata":{"id":"xKaL6kUFgMWt","colab_type":"code","colab":{}},"source":["def load_model():\n","  import pickle\n"," \n","  model_pkl = open(\"svc_model.pkl\", \"rb\")\n","\n","  # Reading the model\n","  model = pickle.load(model_pkl)\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AGN6Rh_S7SPk","colab_type":"text"},"source":["load data"]},{"cell_type":"code","metadata":{"id":"2AElOKtKC3sW","colab_type":"code","colab":{}},"source":["\n","metadata=np.load(\"meta.npz\",allow_pickle=True)['meta']\n","pepole=np.load(\"meta.npz\",allow_pickle=True)['pepole']\n","embedded=np.load(\"meta.npz\",allow_pickle=True)['embedded']\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nxDOHbnA0-d","colab_type":"code","outputId":"0d9756e0-4bf6-48ef-c4ce-4ed3f6d5ca8d","executionInfo":{"status":"ok","timestamp":1558401756221,"user_tz":-120,"elapsed":1030,"user":{"displayName":"Abdelrhman Adel","photoUrl":"","userId":"12215465392683228263"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","from sklearn.preprocessing import LabelEncoder\n","encoder = LabelEncoder()\n","\n","encoder.fit(pepole)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LabelEncoder()"]},"metadata":{"tags":[]},"execution_count":311}]},{"cell_type":"markdown","metadata":{"id":"6rPwAa8k0isN","colab_type":"text"},"source":["preprocessing images\n"]},{"cell_type":"code","metadata":{"id":"iaPLxIhDAEZW","colab_type":"code","colab":{}},"source":["def distance(emb1, emb2):\n","    return np.sum(np.square(emb1 - emb2))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8L2SI2zXs0j","colab_type":"code","colab":{}},"source":["\n","def similarity(v1, v2):\n","    n1 = np.linalg.norm(v1)\n","    n2 = np.linalg.norm(v2)\n","    x1 = np.squeeze(np.asarray(v1))\n","\n","    x2 = np.squeeze(np.asarray(v2))\n","    return np.dot(x1,x2, out=None) / n1 / n2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSPDam360n4B","colab_type":"code","colab":{}},"source":["    \n","from PIL import Image\n","import face_recognition\n","def face_detector(img_path):\n","  faces=[]\n","  image = face_recognition.load_image_file(img_path)\n","  \n","\n","\n","# Find all the faces in the image using a pre-trained convolutional neural network.\n","# This method is more accurate than the default HOG model, but it's slower\n","# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n","# this will use GPU acceleration and perform well.\n","# See also: find_faces_in_picture.py\n","  face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n","\n","  if(len(face_locations)):\n","       for face_location in face_locations:\n","          \n","       # Print the location of each face in this image\n","          top, right, bottom, left = face_location\n","      \n","    # You can access the actual face itself like this:\n","          face_image = image[top:bottom, left:right]\n","      \n","          faces.append(face_image)\n","      \n","      return faces,image\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSrlp-DAx8pk","colab_type":"code","colab":{}},"source":["def image_recognizer(img,model,nn4_small2_pretrained):\n","  \n","  pepole=np.load(\"meta.npz\",allow_pickle=True)['pepole']\n","  from sklearn.preprocessing import LabelEncoder\n","  encoder = LabelEncoder()\n","\n","  encoder.fit(pepole)\n"," \n","\n","  image = align_image(img)\n","  if(image is not None):\n","    image = (image / 255.).astype(np.float32)\n","    emb = nn4_small2_pretrained.predict(np.expand_dims(image, axis=0))\n"," \n","    image_pred = model.predict(emb)\n","  \n","    \n","    image_identity = encoder.inverse_transform(image_pred)[0]\n","  \n","       \n"," \n","    \n","  else:\n","    image_identity='none'\n","  return image_identity,image"],"execution_count":0,"outputs":[]}]}